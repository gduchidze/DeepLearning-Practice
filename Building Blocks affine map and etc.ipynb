{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "RI25ccfbxP9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eLJMLfP-xHmz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSx1ba9uxTQk",
        "outputId": "78023bff-b111-4e81-96a0-10273c0118f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 271kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.03MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 5.17MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "\n",
        "# Define test_data similar to training_data, but with train=False\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,  # Set train=False for test data\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVySiML5yJtX",
        "outputId": "4c22a1bf-6aa6-44de-b003-4efb45b1d1d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\"\n",
        ")\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj4ZhDjdycx6",
        "outputId": "76842ac8-07d2-4afe-a96b-bcc903d049a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "a = []\n",
        "b = []\n",
        "for i in range(1000000):\n",
        "    a.append(i)\n",
        "    b.append(i)\n",
        "a = np.array(a)\n",
        "b = np.array(b)\n",
        "tic = time.time(\n",
        ")\n",
        "c = np.dot(a, b)\n",
        "toc = time.time()\n",
        "print(c)\n",
        "print(\"Vectorized version:\" + str(1000 * (toc - tic)) + \"ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7VnCTYWzVQf",
        "outputId": "a9408be6-203f-47b8-ef77-f2b97ec1b009"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333332833333500000\n",
            "Vectorized version:2.4175643920898438ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "tic = time.time()\n",
        "for i in range(1000000):\n",
        "    c += a[i] * b[i]\n",
        "toc = time.time()\n",
        "print(f\"Non-vectorized version: {1000*(toc - tic)}ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP1WDum8-L8g",
        "outputId": "d90b1d0e-42a7-4cc3-cca3-4ba4a2a7b050"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-vectorized version: 512.9342079162598ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfWJaY6q-XuX",
        "outputId": "38edb698-a539-42e1-bc58-57d90e8dfbe9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dd29bbcddf0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin = nn.Linear(5, 3)  # maps from R^5 to R^3, parameters A, b\n",
        "lin = nn.Linear(5, 3)  # maps from R^5 to R^3, parameters A, b\n",
        "# data is 2x5.  A maps from 5 to 3... can we map \"data\" under A?\n",
        "data = torch.randn(2, 5)\n",
        "print(lin(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdGrMrzGEJ1o",
        "outputId": "29131469-f65e-47f0-e05b-a14e2a6d1de7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4163, -0.6120,  0.1900],\n",
            "        [ 0.4151,  1.1108, -0.8343]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.rand(2, 2)\n",
        "print(data)\n",
        "print(F.relu(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BAqpupqEfsr",
        "outputId": "2cb15b2f-d8fe-438e-b683-fe903024695a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6642, 0.6099],\n",
            "        [0.6818, 0.7479]])\n",
            "tensor([[0.6642, 0.6099],\n",
            "        [0.6818, 0.7479]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.rand(5)\n",
        "print(data)\n",
        "print(F.softmax(data, dim=0))\n",
        "print(F.softmax(data, dim=0).sum())\n",
        "print(F.log_softmax(data, dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO_XUXwlEuLE",
        "outputId": "fc5bb8f0-db49-4ea1-883a-8dd5938ba05e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0369, 0.7517, 0.1484, 0.1227, 0.5304])\n",
            "tensor([0.1452, 0.2966, 0.1623, 0.1582, 0.2378])\n",
            "tensor(1.0000)\n",
            "tensor([-1.9299, -1.2152, -1.8185, -1.8441, -1.4365])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Logistic Regression Bag-of-Words classifier\n",
        "\n",
        "data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
        "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
        "        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
        "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
        "\n",
        "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
        "             (\"it is lost on me\".split(), \"ENGLISH\")]\n",
        "\n",
        "word_to_ix = {}\n",
        "# Simple Tokenization Example ???? (Index into the bag of words vector as a dict)\n",
        "for sent, _ in data + test_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "print(word_to_ix)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXX_GMCkE-iY",
        "outputId": "f7ac2419-3ea0-4b40-8e6d-6b3d227f131d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(word_to_ix)\n",
        "NUM_LABELS = 2\n",
        "\n",
        "\n",
        "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
        "\n",
        "    def __init__(self, num_labels, vocab_size):\n",
        "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
        "        # just always do it in an nn.Module\n",
        "        super(BoWClassifier, self).__init__()\n",
        "\n",
        "        # Define the parameters that you will need.  In this case, we need A and b,\n",
        "        # the parameters of the affine mapping.\n",
        "        # Torch defines nn.Linear(), which provides the affine map.\n",
        "        # Make sure you understand why the input dimension is vocab_size\n",
        "        # and the output is num_labels!\n",
        "        self.linear = nn.Linear(vocab_size, num_labels)\n",
        "\n",
        "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
        "        # to worry about that here\n",
        "\n",
        "    def forward(self, bow_vec):\n",
        "        # Pass the input through the linear layer,\n",
        "        # then pass that through log_softmax.\n",
        "        # Many non-linearities and other functions are in torch.nn.functional\n",
        "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
        "\n",
        "\n",
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence:\n",
        "        vec[word_to_ix[word]] += 1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "\n",
        "def make_target(label, label_to_ix):\n",
        "    return torch.LongTensor([label_to_ix[label]])\n",
        "\n",
        "\n",
        "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
        "\n",
        "# the model knows its parameters.  The first output below is A, the second is b.\n",
        "# Whenever you assign a component to a class variable in the __init__ function\n",
        "# of a module, which was done with the line\n",
        "# self.linear = nn.Linear(...)\n",
        "# Then through some Python magic from the PyTorch devs, your module\n",
        "# (in this case, BoWClassifier) will store knowledge of the nn.Linear's parameters\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "# To run the model, pass in a BoW vector\n",
        "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    sample = data[0]\n",
        "    bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
        "    log_probs = model(bow_vector)\n",
        "    print(log_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9yFfLkDGG-v",
        "outputId": "0ec17745-8a4a-4990-a60b-52251d3d8c39"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0755, -0.0921,  0.0111,  0.1420, -0.1380,  0.0921,  0.1260,  0.1918,\n",
            "         -0.1373,  0.0475, -0.1450,  0.1674, -0.0761,  0.1181,  0.0058, -0.0153,\n",
            "         -0.0063,  0.0333,  0.0924,  0.0315,  0.0598, -0.1764,  0.1429,  0.1710,\n",
            "          0.1621,  0.1450],\n",
            "        [-0.1415, -0.0727,  0.1729, -0.1494,  0.1779, -0.1542, -0.1381,  0.0959,\n",
            "         -0.1409, -0.0449,  0.1427,  0.1553,  0.1855, -0.0398, -0.1524,  0.1931,\n",
            "         -0.0418, -0.0807,  0.0478, -0.1371,  0.1289,  0.1229, -0.1556, -0.1611,\n",
            "         -0.0172,  0.0824]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0057, -0.0994], requires_grad=True)\n",
            "tensor([[-0.5980, -0.7983]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for instance, label in test_data:\n",
        "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
        "        log_probs = model(bow_vec)\n",
        "        print(log_probs)\n",
        "print(next(model.parameters())[:, word_to_ix[\"creo\"]])\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Usually you want to pass over the training data several times.\n",
        "# 100 is much bigger than on a real data set, but real datasets have more than\n",
        "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
        "for epoch in range(100):\n",
        "    for instance, label in data:\n",
        "        # Step 1. Remember that PyTorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
        "        # Tensor as an integer. For example, if the target is SPANISH, then\n",
        "        # we wrap the integer 0. The loss function then knows that the 0th\n",
        "        # element of the log probabilities is the log probability\n",
        "        # corresponding to SPANISH\n",
        "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
        "        target = make_target(label, label_to_ix)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        log_probs = model(bow_vec)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss = loss_function(log_probs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for instance, label in test_data:\n",
        "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
        "        log_probs = model(bow_vec)\n",
        "        print(log_probs)\n",
        "\n",
        "# Index corresponding to Spanish goes up, English goes down!\n",
        "print(next(model.parameters())[:, word_to_ix[\"creo\"]])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYlCifLDOs-j",
        "outputId": "297058b4-6355-4e34-dd0a-fea6acc08175"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5419, -0.8714]])\n",
            "tensor([[-0.6662, -0.7208]])\n",
            "tensor([-0.1450,  0.1427], grad_fn=<SelectBackward0>)\n",
            "tensor([[-0.0999, -2.3528]])\n",
            "tensor([[-2.9018, -0.0565]])\n",
            "tensor([ 0.3088, -0.3112], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mvuqxn9QPeKY"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}